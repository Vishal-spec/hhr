{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.259</th>\n",
       "      <th>0.260</th>\n",
       "      <th>0.261</th>\n",
       "      <th>0.262</th>\n",
       "      <th>0.263</th>\n",
       "      <th>0.264</th>\n",
       "      <th>0.265</th>\n",
       "      <th>0.266</th>\n",
       "      <th>0.267</th>\n",
       "      <th>1.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.259  0.260  0.261  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.262  0.263  0.264  0.265  0.266  0.267  1.5  \n",
       "0      0      0      0      0      0      0    1  \n",
       "1      0      0      0      0      0      0    1  \n",
       "2      0      0      0      0      0      0    1  \n",
       "3      0      0      0      0      0      0    1  \n",
       "4      0      0      0      0      0      0    1  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,Activation,ZeroPadding2D,BatchNormalization,Flatten,Conv2D\n",
    "from keras.layers import AveragePooling2D,MaxPooling2D,Dropout,GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.utils import np_utils,print_summary\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "data=pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71500, 1024)\n",
      "[29 32 35 ... 27 18 18]\n"
     ]
    }
   ],
   "source": [
    "dataset=np.array(data)\n",
    "np.random.shuffle(dataset)\n",
    "X=dataset\n",
    "Y=dataset\n",
    "X=X[:,0:1024]\n",
    "print(str(X.shape))\n",
    "Y=Y[:,1024]\n",
    "print(Y)\n",
    "X_train=X[0:70000,:]\n",
    "X_train=X_train/255\n",
    "X_test=X[70000:72001,:]\n",
    "X_test=X_test/255\n",
    "Y=Y.reshape(Y.shape[0],1)\n",
    "Y_train=Y[0:70000,:]\n",
    "Y_train=Y_train.T\n",
    "Y_test=Y[70000:72001,:]\n",
    "Y_test=Y_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "j=0\n",
    "# default format can be changed as needed\n",
    "def createFileList(myDir, format='.png'):\n",
    "    fileList = []\n",
    "    print(myDir)\n",
    "    for root, dirs, files in os.walk(myDir, topdown=True):\n",
    "        for name in files:\n",
    "            if name.endswith(format):\n",
    "                fullName = os.path.join(root, name)\n",
    "                fileList.append(fullName)\n",
    "    return fileList\n",
    "\n",
    "# load the original image\n",
    "mydir=[\"data\\Train\\character_1_ka\",\"data\\Train\\character_2_kha\",\"data\\Train\\character_3_ga\",\"data\\Train\\character_4_gha\",\"data\\Train\\character_5_kna\",\"data\\Train\\character_6_cha\",\"data\\Train\\character_7_chha\",\"data\\Train\\character_8_ja\",\"data\\Train\\character_9_jha\",\"data\\Train\\character_10_yna\",\"data\\Train\\character_11_taamatar\",\"data\\Train\\character_12_thaa\",\"data\\Train\\character_13_daa\",\"data\\Train\\character_14_dhaa\",\"data\\Train\\character_15_adna\",\"data\\Train\\character_16_tabala\",\"data\\Train\\character_17_tha\",\"data\\Train\\character_18_da\",\"data\\Train\\character_19_dha\",\"data\\Train\\character_20_na\",\"data\\Train\\character_21_pa\",\"data\\Train\\character_22_pha\",\"data\\Train\\character_23_ba\",\"data\\Train\\character_24_bha\",\"data\\Train\\character_25_ma\",\"data\\Train\\character_26_yaw\",\"data\\Train\\character_27_ra\",\"data\\Train\\character_28_la\",\"data\\Train\\character_29_waw\",\"data\\Train\\character_30_motosaw\",\"data\\Train\\character_31_petchiryakha\",\"data\\Train\\character_32_patalosaw\",\"data\\Train\\character_33_ha\",\"data\\Train\\character_34_chhya\",\"data\\Train\\character_35_tra\",\"data\\Train\\character_36_gya\"]\n",
    "for i in mydir:\n",
    "    j=j+1\n",
    "    myFileList=createFileList(i)\n",
    "    for file in myFileList:\n",
    "        img_file = Image.open(file)\n",
    "        #img_file.show()\n",
    "\n",
    "        # get original image parameters...\n",
    "        width, height = img_file.size\n",
    "        format = img_file.format\n",
    "        mode = img_file.mode\n",
    "\n",
    "        # Make image Greyscale\n",
    "        img_grey = img_file.convert('L')\n",
    "        #img_grey.save('result.png')\n",
    "        #img_grey.show()\n",
    "    \n",
    "        # Save Greyscale values\n",
    "        value = np.asarray(img_grey.getdata(), dtype=np.int).reshape((img_grey.size[1], img_grey.size[0]))\n",
    "        value=np.append(value,j)\n",
    "        value = value.flatten()\n",
    "        with open(\"data.csv\", 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "j=0\n",
    "# default format can be changed as needed\n",
    "def createFileList(myDir, format='.png'):\n",
    "    fileList = []\n",
    "    print(myDir)\n",
    "    for root, dirs, files in os.walk(myDir, topdown=True):\n",
    "        for name in files:\n",
    "            if name.endswith(format):\n",
    "                fullName = os.path.join(root, name)\n",
    "                fileList.append(fullName)\n",
    "    return fileList\n",
    "\n",
    "# load the original image\n",
    "mydir=[\"data\\Test\\character_1_ka\",\"data\\Test\\character_2_kha\",\"data\\Test\\character_3_ga\",\"data\\Test\\character_4_gha\",\"data\\Test\\character_5_kna\",\"data\\Test\\character_6_cha\",\"data\\Test\\character_7_chha\",\"data\\Test\\character_8_ja\",\"data\\Test\\character_9_jha\",\"data\\Test\\character_10_yna\",\"data\\Test\\character_11_taamatar\",\"data\\Test\\character_12_thaa\",\"data\\Test\\character_13_daa\",\"data\\Test\\character_14_dhaa\",\"data\\Test\\character_15_adna\",\"data\\Test\\character_16_tabala\",\"data\\Test\\character_17_tha\",\"data\\Test\\character_18_da\",\"data\\Test\\character_19_dha\",\"data\\Test\\character_20_na\",\"data\\Test\\character_21_pa\",\"data\\Test\\character_22_pha\",\"data\\Test\\character_23_ba\",\"data\\Test\\character_24_bha\",\"data\\Test\\character_25_ma\",\"data\\Test\\character_26_yaw\",\"data\\Test\\character_27_ra\",\"data\\Test\\character_28_la\",\"data\\Test\\character_29_waw\",\"data\\Test\\character_30_motosaw\",\"data\\Test\\character_31_petchiryakha\",\"data\\Test\\character_32_patalosaw\",\"data\\Test\\character_33_ha\",\"data\\Test\\character_34_chhya\",\"data\\Test\\character_35_tra\",\"data\\Test\\character_36_gya\"]\n",
    "for i in mydir:\n",
    "    j=j+1\n",
    "    myFileList=createFileList(i)\n",
    "    for file in myFileList:\n",
    "        img_file = Image.open(file)\n",
    "        #img_file.show()\n",
    "\n",
    "        # get original image parameters...\n",
    "        width, height = img_file.size\n",
    "        format = img_file.format\n",
    "        mode = img_file.mode\n",
    "\n",
    "        # Make image Greyscale\n",
    "        img_grey = img_file.convert('L')\n",
    "        #img_grey.save('result.png')\n",
    "        #img_grey.show()\n",
    "    \n",
    "        # Save Greyscale values\n",
    "        value = np.asarray(img_grey.getdata(), dtype=np.int).reshape((img_grey.size[1], img_grey.size[0]))\n",
    "        value=np.append(value,j)\n",
    "        value = value.flatten()\n",
    "        with open(\"data.csv\", 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples:70000\n",
      "number of test examples:1500\n",
      "X_train shape:(70000, 1024)\n",
      "Y_train shape:(1, 70000)\n",
      "X_Test shape:(1500, 1024)\n",
      "Y_test shape:(1, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples:\"+str(X_train.shape[0]))\n",
    "\n",
    "print(\"number of test examples:\"+str(X_test.shape[0]))\n",
    "print(\"X_train shape:\"+str(X_train.shape))\n",
    "print(\"Y_train shape:\"+str(Y_train.shape))\n",
    "print(\"X_Test shape:\"+str(X_test.shape))\n",
    "print(\"Y_test shape:\"+str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(70000, 32, 32, 1)\n",
      "Y_train shape:(70000, 37)\n"
     ]
    }
   ],
   "source": [
    "image_x=32\n",
    "image_y=32\n",
    "train_y=np_utils.to_categorical(Y_train)\n",
    "test_y=np_utils.to_categorical(Y_test)\n",
    "train_y=train_y.reshape(train_y.shape[1],train_y.shape[2])\n",
    "test_y=test_y.reshape(test_y.shape[1],test_y.shape[2])\n",
    "X_train=X_train.reshape(X_train.shape[0],image_x,image_y,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],image_x,image_y,1)\n",
    "print(\"X_train shape:\"+str(X_train.shape))\n",
    "print(\"Y_train shape:\"+str(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(image_x,image_y):\n",
    "    num_of_classes=37\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=32,kernel_size=(5,5),input_shape=(image_x,image_y,1),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n",
    "    model.add(Conv2D(64,(5,5),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5),strides=(5,5),padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_of_classes,activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    filepath=\"devanagari.h5\"\n",
    "    checkpoint1=ModelCheckpoint(filepath,monitor=\"val_acc\",verbose=1,save_best_only=True,mode=\"max\")\n",
    "    callbacks_list=[checkpoint1]\n",
    "    return model,callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 1500 samples\n",
      "Epoch 1/1\n",
      "70000/70000 [==============================] - 114s 2ms/step - loss: 0.8285 - accuracy: 0.7648 - val_loss: 0.4248 - val_accuracy: 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Error: 12.27%\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                9509      \n",
      "=================================================================\n",
      "Total params: 61,605\n",
      "Trainable params: 61,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model,callbacks_list=keras_model(image_x,image_y)\n",
    "model.fit(X_train,train_y,validation_data=(X_test,test_y),epochs=1,batch_size=64,callbacks=callbacks_list)\n",
    "scores=model.evaluate(X_test,test_y,verbose=0)\n",
    "print(\"CNN Error: %.2f%%\"%(100-scores[1]*100))\n",
    "print_summary(model)\n",
    "model.save(\"devanagiri.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000001EA3B91DC08>\n"
     ]
    }
   ],
   "source": [
    "model1=load_model(\"devanagiri.h5\")\n",
    "print(model1)\n",
    "letter_count={0:\"CHECK\",1:\"01_ka\",2:\"02_kha\",3:\"03_ga\",4:\"04_gha\",5:\"05_nya\",6:\"06_cha\",7:\"07_chha\",8:\"08_ja\",9:\"09_jha\",10:\"10_yna\",11:\"11_tamataar\",12:\"12_tha\",13:\"13_dha\",14:\"14_daa\",15:\"15_adna\",16:\"16_tabala\",17:\"17_thaa\",18:\"18_dha\",19:\"19_dhaa\",20:\"20_na\",21:\"21_pa\",22:\"22_pha\",23:\"23_ba\",24:\"24_bha\",25:\"25_ma\",26:\"26_ya\",27:\"27_ra\",28:\"28_la\",29:\"29_va\",30:\"30_motasaw\",31:\"31_patchiryaka\",32:\"32_patalosa\",33:\"33_ha\",34:\"34_chya\",35:\"35_tra\",36:\"36_gna\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_predict(model,image):\n",
    "    processed=keras_process_image(image)\n",
    "    print(\"processed:\"+str(processed.shape))\n",
    "    pred_probab=model.predict(processed)[0]\n",
    "    pred_class=list(pred_probab).index(max(pred_probab))\n",
    "    return max(pred_probab),pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_process_image(img):\n",
    "    image_x=32\n",
    "    image_y=32\n",
    "    img=cv2.resize(img,(image_x,image_y))\n",
    "    img=np.array(img,dtype=np.float32)\n",
    "    img=np.reshape(img,(-1,image_x,image_y,1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "Lower_blue=np.array([110,50,50])\n",
    "Upper_blue=np.array([130,255,255])\n",
    "pred_class=0\n",
    "pts=deque(maxlen=512)\n",
    "blackboard=np.zeros((480,640,3), dtype = np.uint8)\n",
    "digit=np.zeros((200,200,3),dtype=np.uint8)\n",
    "while (cap.isOpened()):\n",
    "    ret,img=cap.read()\n",
    "    img=cv2.flip(img,1)\n",
    "    imgHSV=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    mask=cv2.inRange(imgHSV,Lower_blue,Upper_blue)\n",
    "    blur=cv2.medianBlur(mask,15)\n",
    "    blur=cv2.GaussianBlur(blur,(5,5),0)\n",
    "    thresh=cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    cnts=cv2.findContours(thresh.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)[1]\n",
    "    center=None\n",
    "    if len(cnts)>=1:\n",
    "        contour=max(cnts, key = cv2.contourArea)\n",
    "        if cv2.contourArea(contour)>250:\n",
    "            ((x,y),radius)=cv2.minEnclosingCircle(contour)\n",
    "            cv2.circle(img,(int(x),int(y)),int(radius),(0,255,255),2)\n",
    "            cv2.circle(img,center,5,(0,0,255),-1)\n",
    "            M=cv2.moments(contour)\n",
    "            center=(int(M[\"m10\"]/M[\"m00\"]),int(M[\"m01\"]/M[\"m00\"]))\n",
    "            pts.appendleft(center)\n",
    "            for i in range(1,len(pts)):\n",
    "                if pts[i-1] is None or pts[i] is None:\n",
    "                    continue\n",
    "                cv2.line(blackboard,pts[i-1],pts[i],(255,255,255),10)\n",
    "                cv2.line(img,pts[i-1],pts[i],(0,0,255),5)\n",
    "    elif len(cnts)==0:\n",
    "        if len(pts)!=[]:\n",
    "            blackboard_gray=cv2.cvtColor(blackboard,cv2.COLOR_BGR2GRAY)\n",
    "            blur1=cv2.medianBlur(blackboard_gray,15)\n",
    "            blur1=cv2.GaussianBlur(blur1,(5,5),0)\n",
    "            thresh1=cv2.threshold(blur1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "            blackboard_cnts=cv2.findContours(thresh1.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)[1]\n",
    "            if len(blackboard_cnts)>=1:\n",
    "                cnt=max(blackboard_cnts,key=cv2.contourArea)\n",
    "                print(cv2.contourArea(cnt))\n",
    "                if cv2.contourArea(cnt)>2000:\n",
    "                    x,y,w,h=cv2.boundingRect(cnt)\n",
    "                    digit=blackboard_gray[y:y+h,x:x+w]\n",
    "                    pred_probab,pred_class=keras_predict(model1,digit)\n",
    "                    print(pred_class,pred_probab)\n",
    "            pts=deque(maxlen=512)\n",
    "            blackboard=np.zeros((480,640,3),dtype=np.uint8)\n",
    "        cv2.putText(img,\"Conv Network:\"+str(letter_count[pred_class]),(10,470),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        cv2.imshow(\"Frame\",img)\n",
    "        cv2.imshow(\"Contotours\",thresh)\n",
    "        k=cv2.waitKey(10)\n",
    "        if k==27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
